<!DOCTYPE html>
<html>

<head>
    <meta charset="utf-8">
    <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
    <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>USTC-TD-dataset</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="https://avatars.githubusercontent.com/u/116997363">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>

    <nav class="navbar" role="navigation" aria-label="main navigation">
        <div class="navbar-brand">
            <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
                <span aria-hidden="true"></span>
            </a>
        </div>
        <div class="navbar-menu">
            <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
                <a class="navbar-item" href="https://ustc-ivclab.github.io/">
                    <span class="icon">
                        <i class="fas fa-home"></i>
                    </span>
                </a>

                <!-- <div class="navbar-item has-dropdown is-hoverable">
                    <a class="navbar-link">
                        More Research
                    </a>
                    <div class="navbar-dropdown">
                        <a class="navbar-item" href="">
                        </a>
                    </div>
                </div> -->
            </div>

        </div>
    </nav>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">USTC-TD: A Test Database and Benchmark for Learned
                            Image and Video Compression</h1>
                        <div class="is-size-5 publication-authors">
                            <!-- Author -->
                            <span class="author-block">
                                <a href="https://github.com/ustc-milkbrother">Zhuoyuan Li</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://junqi98.github.io/">Junqi Liao</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://www.neuralcodec.come">Xihua Sheng</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://github.com/zht1999">Haotian Zhang</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="http://home.ustc.edu.cn/~lyq010303/">Yuqi Li</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://github.com/Austin4USTC">Chuanbo Tang</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://esakak.world/PersonalPage">Yifan Bian</a><sup>1</sup>,</span>
                            <span class="author-block">
                                <a href="https://github.com/mrliyao">Yao Li</a><sup>1</sup>,</span>
                            <span class="author-block"> <a href="https://blog.csdn.net/weixin_43721070">Xinmin
                                    Feng</a><sup>1</sup>,</span>
                            <span class="author-block"> <a href="https://blog.csdn.net/weixin_43721070">Changsheng
                                    Gao</a><sup>1</sup>,</span>
                            <span class="author-block"> <a href="https://faculty.ustc.edu.cn/lil1/en">Li
                                    Li</a><sup>1</sup>,</span>
                            <span class="author-block"> <a href="https://faculty.ustc.edu.cn/dongeliu/">Dong
                                    Liu</a><sup>1</sup>,</span>
                        </div>

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>University of Science and Technology of China</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="https://arxiv.org/abs/2011.12948"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="ai ai-arxiv"></i>
                                        </span>
                                        <span>arXiv</span>
                                    </a>
                                </span>
                                <!-- Dataset Link. -->
                                <span class="link-block">
                                    <a href="https://github.com/Junqi98/USTC-TD-dataset"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="far fa-images"></i>
                                        </span>
                                        <span>Data</span>
                                    </a>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!--Top Image-->
    <div class="container is-max-desktop">
        <center><img src="static/images/datasets/top.webp" border="0" width="100%"></center>
        <!-- <h2 class="subtitle has-text-centered"> -->
        <div align="center">
            <p style="text-align:justify; text-justify:inter-ideograph;width:100%">Figure 1. Examples of USTC Image Test
                Dataset. </p>
        </div><br>
    </div>



    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Learnable end-to-end (E2E) image/video compression
                            has been a remarkable research for both academia and
                            industry in recent years. Testing datasets, especially high quality
                            image/video datasets are desirable for efficient validation of
                            related researches, practical applications and standardization
                            activities. In this report, we put forward a test database for
                            compression-related systems, named USTC-TD. The proposed
                            database has been applied in the image/video compression
                            challenge of IEEE International Conference on Visual Com-
                            munications and lmage Processing (VCIP Challenge) in 2022
                            and 2023. USTC-TD contains 40 images at 2160p (4K) spatial
                            resolution and 10 sequences at 1080P spatial resolution, which is
                            captured in diverse content covering different texture and scene
                            types. Furthermore, we evaluate the proposed database with
                            different metrics (PSNR, MS-SSIM, et al.) on recent advanced
                            E2E compression algorithms, such as iWave++, DVC, CANF,
                            DCVC, outstanding schemes of VCIP Challenge, standardization
                            activities (High Efficiency Video Coding (HEVC), Versatile Video
                            Coding (VVC), IEEE 1857.11, AVS-EEM), and et al. We provide
                            an extended baseline for state-of-the-art compression systems
                            benchmarked on USTC-TD. The database and benchmark data
                            are released on website
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <section class="section">
        <div class="container is-max-desktop">

            <div class="columns is-centered">
                <!-- Image Dataset -->
                <div class="column">
                    <div class="content">
                        <h2 class="title is-3">Image Test Dataset</h2>
                        <!--Image 2022-->
                        <p>
                            Our proposed database can cover more scene types with
                            more environment conditions (texture, illumination, motion, et
                            al) compared to previous image database, and try to simulate the data in the real-world
                            coding trans-
                            mission scenes, which makes the evaluation of experimental
                            results more closer to the actual application.
                        </p>
                        <center><img src="static/images/datasets/2022.webp" border="0" width="100%"></center>
                        <!-- <h2 class="subtitle has-text-centered"> -->
                        <div align="center">
                            <p style="text-align:justify; text-justify:inter-ideograph;width:100%">Figure 2.
                                Illustration of the image database in USTC-TD 2022. </p>
                        </div><br>
                        <!--Image 2023-->
                        <p>Compared to USTD-TD 2022, USTC-TD 2023 considers more extreme conditions in real-world
                            scenes.</p>
                        <center><img src="static/images/datasets/2023.webp" border="0" width="100%"></center>
                        <!-- <h2 class="subtitle has-text-centered"> -->
                        <div align="center">
                            <p style="text-align:justify; text-justify:inter-ideograph;width:100%">Figure 2.
                                Illustration of the image database in USTC-TD 2023. </p>
                        </div><br>
                    </div>
                </div>
                <!--/ Image Dataset. -->
            </div>

            <div class="columns is-centered">
                <!-- Video Dataset -->
                <div class="column">
                    <div class="content">
                        <h2 class="title is-3">Video Test Dataset</h2>
                        <!--Video-->
                        <p>
                            Our proposed database can further cover
                            more characteristics of video content.
                            Compared to the image data, temporal-domain
                            properties are unique to video data, especially in diverse motion types with more
                            environmental
                            conditions in natural videos.
                        </p>

                        <div class="gif">
                            <img src="static/images/datasets/videos/1.gif">
                            <img src="static/images/datasets/videos/2.gif">
                            <img src="static/images/datasets/videos/3.gif">
                            <img src="static/images/datasets/videos/4.gif">
                            <img src="static/images/datasets/videos/5.gif">
                        </div>
                        <div class="gif">
                            <img src="static/images/datasets/videos/6.gif">
                            <img src="static/images/datasets/videos/7.gif">
                            <img src="static/images/datasets/videos/8.gif">
                            <img src="static/images/datasets/videos/9.gif">
                            <img src="static/images/datasets/videos/10.gif">
                        </div>


                        <div align="center">
                            <p style="text-align:justify; text-justify:inter-ideograph;width:100%">Figure 3.
                                Illustration of the video database in USTC-TD 2022. </p>
                        </div><br>
                    </div>
                </div>
                <!--/ Video Dataset -->
            </div>

            <!-- Statistic. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Dataset Statistics</h2>
                    <!-- Image. -->
                    <h3 class="title is-4">Image Method</h3>
                    <div class="content has-text-justified">
                        <p>
                            We can also animate the scene by interpolating the deformation latent codes of two input
                            frames. Use the slider here to linearly interpolate between the left frame and the right
                            frame.
                        </p>
                        <div class="columns is-centered">
                            <table border="0.6">
                                <caption><b>TABLE 1. BD-RATE (%) FOR MS-SSIM.</b><br>
                                    <font color="#737373">The anchor is VTM.</font>
                                </caption>
                                <!-- The newly built MOSE has the longest video duration and largest objects and annotations. More important, the most notable feature of MOSE is that it contains lots of crowds, occlusions, and disappearance-reappearance objects, which provide more complex scenarios for VOS. -->
                                <tbody>
                                    <tr>
                                        <th align="right" bgcolor="#E6E6FA"></th>
                                        <th align="center" bgcolor="#E6E6FA">
                                            <a href="https://web.engr.oregonstate.edu/~lif/SegTrack2/dataset.html"
                                                target="_blank">VTM</a>
                                        </th>
                                    </tr>
                                    <tr>
                                        <td align="right">ClassB</td>
                                        <td align="center">0.0</td>
                                    </tr>
                                    <tr>
                                        <td align="right" bgcolor="ECECEC">ClassC</td>
                                        <td align="center" bgcolor="ECECEC">0.0</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                    </div>
                    <br />
                    <!--/ Image. -->
                    <!-- Video. -->
                    <h3 class="title is-4">Video Method</h3>
                    <div class="content has-text-justified">
                        <p>
                            We can also animate the scene by interpolating the deformation latent codes of two input
                            frames. Use the slider here to linearly interpolate between the left frame and the right
                            frame.
                        </p>
                    </div>
                    <br />
                    <!--/ Video. -->
                </div>
            </div>
            <!--/ Animation. -->


            <!-- Concurrent Work. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">Related Links</h2>
                    <div class="content has-text-justified">
                        <p>
                            There's a lot of excellent work that was introduced around the same time as ours.
                        </p>
                        <p>
                            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a>
                            introduces an idea similar to our windowed
                            position encoding for coarse-to-fine optimization.
                        </p>
                    </div>
                </div>
            </div>
            <!--/ Concurrent Work. -->

        </div>
    </section>

    <!--Bibtex-->
    <section class="section" id="BibTeX">
        <div class="container is-max-desktop content">
            <h2 class="title">BibTeX</h2>
            <pre><code>@article{park2021nerfies,
                author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
                title     = {Nerfies: Deformable Neural Radiance Fields},
                journal   = {ICCV},
                year      = {2021},
                }</code></pre>
        </div>
    </section>

    <section class="section" id="BibTeX">
        <div class="container is-max-desktop">
            <h2 class="title is-3">Contributors</h2>
            <h3 class="title is-4">Supervisors</h3>
            <div class="person">
                <div class="round-1-4" style="text-align: center">
                    <div style="padding-left: 15%; padding-right: 15%">
                        <div class="round">
                            <a href="https://faculty.ustc.edu.cn/dongeliu" target="_blank">
                                <img src="static/images/authors/ld.jpg" alt="Dong Liu" class="roundimg">
                            </a>
                        </div>
                        <p style="line-height: 130%;">Dong Liu<br></p>
                    </div>
                </div>
                <div class="round-1-4" style="text-align: center">
                    <div style="padding-left: 15%; padding-right: 15%">
                        <div class="round">
                            <a href="https://faculty.ustc.edu.cn/lil1/en" target="_blank">
                                <img src="static/images/authors/ll.jpg" alt="Li Li" class="roundimg">
                            </a>
                        </div>
                        <p style="line-height: 130%;">Li Li<br></p>
                    </div>
                </div>
                <div class="round-1-4" style="text-align: center">
                    <div style="padding-left: 15%; padding-right: 15%">
                        <div class="round">
                            <a href="https://ustc-ivclab.github.io/people/2023/06/01/gao,-changsheng.html" target="_blank">
                                <img src="static/images/authors/gcs.jpg" alt="Changsheng Gao" class="roundimg">
                            </a>
                        </div>
                        <p style="line-height: 130%;">Changsheng Gao<br></p>
                    </div>
                </div>
            </div>
            <h3 class="title is-4">Students</h3>
            <div class="person">
                <div class="round-1-4" style="text-align: center">
                    <div style="padding-left: 15%; padding-right: 15%">
                        <div class="round">
                            <a href="https://github.com/ustc-milkbrother" target="_blank">
                                <img src="static/images/authors/lzy.jpg" alt="Zhuoyuan Li" class="roundimg">
                            </a>
                        </div>
                        <p style="line-height: 130%;">Zhuoyuan Li<br><span style="font-size: 80%">Ph.D.</span></p>
                    </div>
                </div>
                <div class="round-1-4" style="text-align: center">
                    <div style="padding-left: 15%; padding-right: 15%">
                        <div class="round">
                            <a href="https://junqi98.github.io/" target="_blank">
                                <img src="static/images/authors/ljq.jpg" alt="Junqi Liao" class="roundimg">
                            </a>
                        </div>
                        <p style="line-height: 130%;">Junqi Liao<br><span style="font-size: 80%">Ph.D.</span></p>
                    </div>
                </div>
                <div class="round-1-4" style="text-align: center">
                    <div style="padding-left: 15%; padding-right: 15%">
                        <div class="round">
                            <a href="https://www.neuralcodec.com" target="_blank">
                                <img src="static/images/authors/sxh.jpg" alt="Xihua Sheng" class="roundimg">
                            </a>
                        </div>
                        <p style="line-height: 130%;">Xihua Sheng<br><span style="font-size: 80%">Ph.D.</span></p>
                    </div>
                </div>
                <div class="round-1-4" style="text-align: center">
                    <div style="padding-left: 15%; padding-right: 15%">
                        <div class="round">
                            <a href="https://github.com/zht1999" target="_blank">
                                <img src="static/images/authors/zht.jpg" alt="Haotian Zhang" class="roundimg">
                            </a>
                        </div>
                        <p style="line-height: 130%;">Haotian Zhang<br><span style="font-size: 80%">Ph.D.</span></p>
                    </div>
                </div>
                <div class="round-1-4" style="text-align: center">
                    <div style="padding-left: 15%; padding-right: 15%">
                        <div class="round">
                            <a href="https://github.com/lyq133" target="_blank">
                                <img src="static/images/authors/lyq.jpg" alt="Yuqi Li" class="roundimg">
                            </a>
                        </div>
                        <p style="line-height: 130%;">Yuqi Li<br><span style="font-size: 80%">M.S.</span></p>
                    </div>
                </div>
                <div class="round-1-4" style="text-align: center">
                    <div style="padding-left: 15%; padding-right: 15%">
                        <div class="round">
                            <a href="https://github.com/Austin4USTC" target="_blank">
                                <img src="static/images/authors/tcb.jpg" alt="Chuanbo Tang" class="roundimg">
                            </a>
                        </div>
                        <p style="line-height: 130%;">Chuanbo Tang<br><span style="font-size: 80%">Ph.D.</span></p>
                    </div>
                </div>
                <div class="round-1-4" style="text-align: center">
                    <div style="padding-left: 15%; padding-right: 15%">
                        <div class="round">
                            <a href="https://github.com/mrliyao" target="_blank">
                                <img src="static/images/authors/ly.jpg" alt="Yao Li" class="roundimg">
                            </a>
                        </div>
                        <p style="line-height: 130%;">Yao Li<br><span style="font-size: 80%">M.S.</span></p>
                    </div>
                </div>

                <div class="round-1-4" style="text-align: center">
                    <div style="padding-left: 15%; padding-right: 15%">
                        <div class="round">
                            <a href="http://esakak.github.io/PersonalPage" target="_blank">
                                <img src="static/images/authors/byf.jpg" alt="Yifan Bian" class="roundimg">
                            </a>
                        </div>
                        <p style="line-height: 130%;">Yifan Bian<br><span style="font-size: 80%">M.S.</span></p>
                    </div>
                </div>
                <div class="round-1-4" style="text-align: center">
                    <div style="padding-left: 15%; padding-right: 15%">
                        <div class="round">
                            <a href="https://ustc-ivclab.github.io/people/2022/09/01/feng,-xinmin.html" target="_blank">
                                <img src="static/images/authors/fxm.jpg" alt="Xinmin Feng" class="roundimg">
                            </a>
                        </div>
                        <p style="line-height: 130%;">Xinmin Feng<br><span style="font-size: 80%">M.S.</span></p>
                    </div>
                </div>
            </div>
        </div>
    </section>


    <footer class="footer">
        <div class="container">
            <div class="columns is-centered">
                <div class="column is-8">
                    <div class="content">
                        <p>
                            This website is licensed under a <a rel="license"
                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                                Commons Attribution-ShareAlike 4.0 International License</a>.
                        </p>
                        <p>
                            Website source code based on the <a
                                href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page.
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </footer>

</body>

</html>